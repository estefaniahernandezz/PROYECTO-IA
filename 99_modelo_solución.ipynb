{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUbz9fdLAkpR4adbV1TxU5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/estefaniahernandezz/PROYECTO-IA/blob/main/99_modelo_soluci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f-BO7IgR5qJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Ruta base\n",
        "BASE_PATH = \"/content/drive/MyDrive/ARCHIVOS IA\"\n",
        "CSV_PATH = os.path.join(BASE_PATH, \"train.csv\")\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 120)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
        "print(\"Filas, columnas:\", df.shape)\n",
        "df.head()\n",
        "\n",
        "# Quitar espacios raros en nombres de columnas\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# Pasar strings a formato 'bonito': sin espacios al inicio/fin\n",
        "for c in df.select_dtypes(include='object').columns:\n",
        "    df[c] = df[c].astype(str).str.strip()\n",
        "\n",
        "df.head(2)\n",
        "# === Conversión Sí/No/N a 1 y 0 ===\n",
        "def to_binary(v):\n",
        "    if pd.isna(v):\n",
        "        return np.nan\n",
        "    s = str(v).strip().lower()\n",
        "    # limpiar tildes o caracteres extraños\n",
        "    s = s.replace(\"í\", \"i\").replace(\"Ã­\", \"i\").replace(\"á\", \"a\").replace(\"ã\", \"a\")\n",
        "    if s in [\"si\", \"s\", \"yes\", \"y\"]:\n",
        "        return 1\n",
        "    if s in [\"no\", \"n\"]:\n",
        "        return 0\n",
        "    if s in [\"1\", \"true\", \"verdadero\"]:\n",
        "        return 1\n",
        "    if s in [\"0\", \"false\", \"falso\"]:\n",
        "        return 0\n",
        "    return np.nan\n",
        "\n",
        "# aplicar a todas las columnas que tengan Sí/No/N\n",
        "for c in df.columns:\n",
        "    if df[c].astype(str).str.lower().isin([\"si\", \"sí\", \"s\", \"no\", \"n\"]).any():\n",
        "        df[c] = df[c].map(to_binary)\n",
        "\n",
        "df.head(3)\n",
        "\n",
        "\n",
        "# Numéricas: medianas\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "for c in num_cols:\n",
        "    df[c] = df[c].fillna(df[c].median())\n",
        "\n",
        "# Categóricas: \"Desconocido\"\n",
        "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "for c in cat_cols:\n",
        "    df[c] = df[c].fillna(\"Desconocido\")\n",
        "\n",
        "df.isna().mean().sort_values(ascending=False).head(10)\n",
        "\n",
        "df_enc = pd.get_dummies(df, columns=cat_cols, drop_first=False)\n",
        "print(\"Shape después de one-hot:\", df_enc.shape)\n",
        "df_enc.head(2)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_enc[num_cols] = scaler.fit_transform(df_enc[num_cols])\n",
        "df_enc.head(2)\n",
        "\n",
        "# =========================================================\n",
        "# Verificación rápida del preprocesado\n",
        "# =========================================================\n",
        "\n",
        "print(\"Forma final del DataFrame:\", df_enc.shape)\n",
        "print(\"- Filas:\", df_enc.shape[0])\n",
        "print(\"- Columnas:\", df_enc.shape[1])\n",
        "print()\n",
        "\n",
        "# 1. Revisar que no queden valores nulos\n",
        "faltantes = df_enc.isna().sum().sum()\n",
        "print(f\"Total de valores faltantes: {faltantes}\")\n",
        "print()\n",
        "\n",
        "# 2. Estadísticas de columnas numéricas (primeras 10)\n",
        "print(\"Estadísticas de columnas numéricas (primeras 10):\")\n",
        "display(df_enc[num_cols].describe().T[['mean', 'std']].head(10))\n",
        "print()\n",
        "\n",
        "# 3. Ejemplo de columnas One-Hot (departamentos)\n",
        "print(\"Ejemplo de columnas One-Hot (departamentos):\")\n",
        "display(df_enc.filter(like='E_PRGM_DEPARTAMENTO').head(5))\n",
        "print()\n",
        "\n",
        "# 4. Top 10 categorías más comunes (suma de 1's)\n",
        "print(\"Top 10 categorías más comunes (suma de 1's):\")\n",
        "display(df_enc.filter(like='E_PRGM_DEPARTAMENTO').sum().sort_values(ascending=False).head(10))\n",
        "print()\n",
        "\n",
        "\n",
        "# 5. Muestra aleatoria de 5 filas\n",
        "print(\"Muestra aleatoria de 5 filas:\")\n",
        "display(df_enc.sample(5, random_state=42))\n",
        "\n",
        "#========================= Entrega Final =================================\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# =======================================================\n",
        "# 1) Cargar train_preprocesado y test\n",
        "# =======================================================\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/ARCHIVOS IA/train_preprocesado.csv\")\n",
        "test  = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# =======================================================\n",
        "# 2) Reconstruir target\n",
        "# =======================================================\n",
        "target_cols = [\n",
        "    \"RENDIMIENTO_GLOBAL_alto\",\n",
        "    \"RENDIMIENTO_GLOBAL_bajo\",\n",
        "    \"RENDIMIENTO_GLOBAL_medio-alto\",\n",
        "    \"RENDIMIENTO_GLOBAL_medio-bajo\"\n",
        "]\n",
        "\n",
        "train[\"RENDIMIENTO_GLOBAL\"] = train[target_cols].idxmax(axis=1)\n",
        "train[\"RENDIMIENTO_GLOBAL\"] = train[\"RENDIMIENTO_GLOBAL\"].str.replace(\"RENDIMIENTO_GLOBAL_\", \"\")\n",
        "\n",
        "y_full = train[\"RENDIMIENTO_GLOBAL\"]\n",
        "X_full = train.drop(target_cols + [\"RENDIMIENTO_GLOBAL\"], axis=1)\n",
        "\n",
        "# =======================================================\n",
        "# 3) LIMITAR EL DATASET (versión que funcionó)\n",
        "# =======================================================\n",
        "\n",
        "LIMIT = 50000    # <-- ESTE valor era el que funcionó (ajustable)\n",
        "X, _, y, _ = train_test_split(\n",
        "    X_full, y_full,\n",
        "    train_size=LIMIT,\n",
        "    stratify=y_full,\n",
        "    random_state=42\n",
        ")\n",
        "print(\"Tamaño final usado:\", X.shape)\n",
        "\n",
        "# =======================================================\n",
        "# 4) Preprocesado uniforme (X + test)\n",
        "# =======================================================\n",
        "full = pd.concat([X, test], axis=0)\n",
        "\n",
        "# Completar nulos numéricos\n",
        "for c in full.select_dtypes(include=['int64','float64']).columns:\n",
        "    full[c] = full[c].fillna(full[c].median())\n",
        "\n",
        "# Completar nulos categóricos\n",
        "for c in full.select_dtypes(include=['object']).columns:\n",
        "    full[c] = full[c].fillna(\"Desconocido\")\n",
        "\n",
        "# One-hot encoding\n",
        "full_enc = pd.get_dummies(full, drop_first=False)\n",
        "\n",
        "# Separar otra vez\n",
        "X_enc = full_enc.iloc[:len(X)]\n",
        "test_enc = full_enc.iloc[len(X):]\n",
        "\n",
        "# Eliminar duplicadas (clave)\n",
        "X_enc = X_enc.loc[:, ~X_enc.columns.duplicated()]\n",
        "test_enc = test_enc.loc[:, ~test_enc.columns.duplicated()]\n",
        "\n",
        "# Alinear columnas (si falta alguna en test, se llena con 0)\n",
        "test_enc = test_enc.reindex(columns=X_enc.columns, fill_value=0)\n",
        "\n",
        "# =======================================================\n",
        "# 5) Codificar el target\n",
        "# =======================================================\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "\n",
        "# =======================================================\n",
        "# 6) MODELO FINAL (RandomForest optimizado — el que funcionó)\n",
        "# =======================================================\n",
        "\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    max_depth=20,\n",
        "    min_samples_leaf=3,\n",
        "    class_weight=\"balanced\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_enc, y_enc)\n",
        "\n",
        "# =======================================================\n",
        "# 7) Predicción Kaggle\n",
        "# =======================================================\n",
        "test_pred = model.predict(test_enc)\n",
        "test_pred = le.inverse_transform(test_pred)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": test[\"ID\"],\n",
        "    \"RENDIMIENTO_GLOBAL\": test_pred\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"submission.csv generado correctamente.\")\n",
        "submission.head()\n"
      ]
    }
  ]
}